2022-January-28 - friday-meeting
================================

### unicode trickiness

#### The problem...

You have a database, and a search term, and you _know_ the search term is in the database, yet no match is found!

Example...

```
>>> database_words
['hola', 'más', 'qué']
>>> 
>>> 'foo' in database_words
False
>>> 
>>> 'hola' in database_words
True
>>> 
>>> 'más' in database_words  # search word typed in via mac 'option-a' method
True
>>> 
>>> 'qué' in database_words  # search word typed in via mac 'option-e' method
False  # ???
>>> 
```

The above confusing situation is because in the 'database', the last word's accented-letter is two combined unicode-characters, but the search-term is using a single unicode-character for the accented letter 

Here's how `database_words` was created:

```
>>> database_words = ['hola', 'm' + '\u00e1' + 's', 'qu' + '\u0065' + '\u0301']
```

And this is how you'd explicitly create the single unicode-character search term:

```
>>> 'qu' + '\u00e9'
'qué'
>>> 
```

(On the Mac, that accented-e is created via typing `option-e` then `e`.)

There is no way, just by looking, that you can tell which of the two ways of writing that character is being used.


#### examining characters, if curious

```
>>> import unicodedata
>>> 
>>> for c in 'qué':  # typed in via option-e method ('qu' + '\u00e9')
...     print( f'unicode-name, ``{unicodedata.name(c)}``' )
... 
unicode-name, ``LATIN SMALL LETTER Q``
unicode-name, ``LATIN SMALL LETTER U``
unicode-name, ``LATIN SMALL LETTER E WITH ACUTE``
>>> 

>>> for c in 'qué':  # pasted in from database_words, which uses the two combined unicode-characters
...     print( f'unicode-name, ``{unicodedata.name(c)}``' )
... 
unicode-name, ``LATIN SMALL LETTER Q``
unicode-name, ``LATIN SMALL LETTER U``
unicode-name, ``LATIN SMALL LETTER E``
unicode-name, ``COMBINING ACUTE ACCENT``
>>> 
```


#### Dealing with this weird reality...

_Good tools, like solr, generally allow you to not have to worry about this, a search-term encoded one way will generally find content encoded the other way._

If you normalize the data in the database, and normalize the search term, all will work.

The code below normalizes by 'decomposing' single-unicode characters into multiple-unicode characters. Note that we start with the single unicode-character, and transform it into the two combined unicode-characters.

```
>>> decomposed_output = unicodedata.normalize( 'NFKD', 'qu' + '\u00e9' )
>>> 
>>> for c in decomposed_output:
...     print( f'unicode-name, ``{unicodedata.name(c)}``' )
... 
unicode-name, ``LATIN SMALL LETTER Q``
unicode-name, ``LATIN SMALL LETTER U``
unicode-name, ``LATIN SMALL LETTER E``
unicode-name, ``COMBINING ACUTE ACCENT``
>>> 
```


#### So one overall solution... 

Save data in a normalized way...

```
>>> decomposed_database_words = []
>>> 
>>> for word in database_words:
...     decomposed_word = unicodedata.normalize( 'NFKD', word )
...     decomposed_database_words.append( decomposed_word )
... 
>>> decomposed_database_words
['hola', 'más', 'qué']
>>> 

...and then normalize the search-term...

```
>>> search_term = 'qu' + '\u00e9'
>>> 
>>> decomposed_search_term = unicodedata.normalize( 'NFKD', search_term )
>>>
```

...then the search term will find the data...

```
>>> decomposed_search_term in decomposed_database_words
True
>>> 
```
